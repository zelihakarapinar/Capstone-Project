{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Uy-pjy8E7vjY",
    "outputId": "dcaf2213-1e57-4a5f-d38d-f8c9655935f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive') # Mount Google Drive to access datasets and save models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ebx9xkAZ71ew"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "LvpN_kYb8BMZ"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Load the merged and labeled vibration dataset (4096-point windows)\n",
    "file_path = '/content/drive/MyDrive/SAYZEK/beginning/combined_trainingrawdata.csv'\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 253
    },
    "id": "uUHWLwG78OgP",
    "outputId": "c559801d-265b-42ca-fa4e-a514c1c8a01f"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "dataframe"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-e7e15663-13a6-4a0a-95ea-83156410d6ec\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DE_0001</th>\n",
       "      <th>DE_0002</th>\n",
       "      <th>DE_0003</th>\n",
       "      <th>DE_0004</th>\n",
       "      <th>DE_0005</th>\n",
       "      <th>DE_0006</th>\n",
       "      <th>DE_0007</th>\n",
       "      <th>DE_0008</th>\n",
       "      <th>DE_0009</th>\n",
       "      <th>DE_0010</th>\n",
       "      <th>...</th>\n",
       "      <th>DE_4088</th>\n",
       "      <th>DE_4089</th>\n",
       "      <th>DE_4090</th>\n",
       "      <th>DE_4091</th>\n",
       "      <th>DE_4092</th>\n",
       "      <th>DE_4093</th>\n",
       "      <th>DE_4094</th>\n",
       "      <th>DE_4095</th>\n",
       "      <th>DE_4096</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3422</th>\n",
       "      <td>0.772429</td>\n",
       "      <td>0.134321</td>\n",
       "      <td>-0.529778</td>\n",
       "      <td>-1.109404</td>\n",
       "      <td>-1.508383</td>\n",
       "      <td>-1.691628</td>\n",
       "      <td>-1.583761</td>\n",
       "      <td>-1.222469</td>\n",
       "      <td>-0.590860</td>\n",
       "      <td>0.208399</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.091810</td>\n",
       "      <td>0.012158</td>\n",
       "      <td>0.101831</td>\n",
       "      <td>0.159014</td>\n",
       "      <td>0.178508</td>\n",
       "      <td>0.191504</td>\n",
       "      <td>0.213597</td>\n",
       "      <td>0.214897</td>\n",
       "      <td>0.179808</td>\n",
       "      <td>Outer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3423</th>\n",
       "      <td>0.094033</td>\n",
       "      <td>-0.016433</td>\n",
       "      <td>-0.100908</td>\n",
       "      <td>-0.154192</td>\n",
       "      <td>-0.176285</td>\n",
       "      <td>-0.207476</td>\n",
       "      <td>-0.247763</td>\n",
       "      <td>-0.263359</td>\n",
       "      <td>-0.234767</td>\n",
       "      <td>-0.172386</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.407615</td>\n",
       "      <td>-0.338736</td>\n",
       "      <td>-0.213974</td>\n",
       "      <td>-0.050223</td>\n",
       "      <td>0.104430</td>\n",
       "      <td>0.239590</td>\n",
       "      <td>0.344858</td>\n",
       "      <td>0.426733</td>\n",
       "      <td>0.457924</td>\n",
       "      <td>Outer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3424</th>\n",
       "      <td>0.422834</td>\n",
       "      <td>0.330562</td>\n",
       "      <td>0.200601</td>\n",
       "      <td>0.078438</td>\n",
       "      <td>-0.024231</td>\n",
       "      <td>-0.110005</td>\n",
       "      <td>-0.167188</td>\n",
       "      <td>-0.197079</td>\n",
       "      <td>-0.189281</td>\n",
       "      <td>-0.126900</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.028130</td>\n",
       "      <td>0.023855</td>\n",
       "      <td>0.090135</td>\n",
       "      <td>0.148617</td>\n",
       "      <td>0.160313</td>\n",
       "      <td>0.148617</td>\n",
       "      <td>0.118726</td>\n",
       "      <td>0.087535</td>\n",
       "      <td>0.069341</td>\n",
       "      <td>Outer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3425</th>\n",
       "      <td>0.032952</td>\n",
       "      <td>-0.034628</td>\n",
       "      <td>-0.107406</td>\n",
       "      <td>-0.173686</td>\n",
       "      <td>-0.219172</td>\n",
       "      <td>-0.238666</td>\n",
       "      <td>-0.249063</td>\n",
       "      <td>-0.263359</td>\n",
       "      <td>-0.281553</td>\n",
       "      <td>-0.275055</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.230869</td>\n",
       "      <td>-0.169787</td>\n",
       "      <td>-0.054122</td>\n",
       "      <td>0.081037</td>\n",
       "      <td>0.190204</td>\n",
       "      <td>0.269481</td>\n",
       "      <td>0.281177</td>\n",
       "      <td>0.257784</td>\n",
       "      <td>0.225294</td>\n",
       "      <td>Outer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3426</th>\n",
       "      <td>0.149917</td>\n",
       "      <td>0.055045</td>\n",
       "      <td>-0.054122</td>\n",
       "      <td>-0.141196</td>\n",
       "      <td>-0.159390</td>\n",
       "      <td>-0.135997</td>\n",
       "      <td>-0.072316</td>\n",
       "      <td>-0.012534</td>\n",
       "      <td>0.031652</td>\n",
       "      <td>0.094033</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026454</td>\n",
       "      <td>0.074539</td>\n",
       "      <td>0.133022</td>\n",
       "      <td>0.164212</td>\n",
       "      <td>0.172010</td>\n",
       "      <td>0.135621</td>\n",
       "      <td>0.068041</td>\n",
       "      <td>0.005660</td>\n",
       "      <td>-0.058021</td>\n",
       "      <td>Outer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 4097 columns</p>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e7e15663-13a6-4a0a-95ea-83156410d6ec')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-e7e15663-13a6-4a0a-95ea-83156410d6ec button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-e7e15663-13a6-4a0a-95ea-83156410d6ec');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    <div id=\"df-d20ce397-f6be-4e09-857a-2de1ed42009a\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d20ce397-f6be-4e09-857a-2de1ed42009a')\"\n",
       "                title=\"Suggest charts\"\n",
       "                style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "      <script>\n",
       "        async function quickchart(key) {\n",
       "          const quickchartButtonEl =\n",
       "            document.querySelector('#' + key + ' button');\n",
       "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "          try {\n",
       "            const charts = await google.colab.kernel.invokeFunction(\n",
       "                'suggestCharts', [key], {});\n",
       "          } catch (error) {\n",
       "            console.error('Error during call to suggestCharts:', error);\n",
       "          }\n",
       "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "        }\n",
       "        (() => {\n",
       "          let quickchartButtonEl =\n",
       "            document.querySelector('#df-d20ce397-f6be-4e09-857a-2de1ed42009a button');\n",
       "          quickchartButtonEl.style.display =\n",
       "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "        })();\n",
       "      </script>\n",
       "    </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "       DE_0001   DE_0002   DE_0003   DE_0004   DE_0005   DE_0006   DE_0007  \\\n",
       "3422  0.772429  0.134321 -0.529778 -1.109404 -1.508383 -1.691628 -1.583761   \n",
       "3423  0.094033 -0.016433 -0.100908 -0.154192 -0.176285 -0.207476 -0.247763   \n",
       "3424  0.422834  0.330562  0.200601  0.078438 -0.024231 -0.110005 -0.167188   \n",
       "3425  0.032952 -0.034628 -0.107406 -0.173686 -0.219172 -0.238666 -0.249063   \n",
       "3426  0.149917  0.055045 -0.054122 -0.141196 -0.159390 -0.135997 -0.072316   \n",
       "\n",
       "       DE_0008   DE_0009   DE_0010  ...   DE_4088   DE_4089   DE_4090  \\\n",
       "3422 -1.222469 -0.590860  0.208399  ... -0.091810  0.012158  0.101831   \n",
       "3423 -0.263359 -0.234767 -0.172386  ... -0.407615 -0.338736 -0.213974   \n",
       "3424 -0.197079 -0.189281 -0.126900  ... -0.028130  0.023855  0.090135   \n",
       "3425 -0.263359 -0.281553 -0.275055  ... -0.230869 -0.169787 -0.054122   \n",
       "3426 -0.012534  0.031652  0.094033  ...  0.026454  0.074539  0.133022   \n",
       "\n",
       "       DE_4091   DE_4092   DE_4093   DE_4094   DE_4095   DE_4096  Label  \n",
       "3422  0.159014  0.178508  0.191504  0.213597  0.214897  0.179808  Outer  \n",
       "3423 -0.050223  0.104430  0.239590  0.344858  0.426733  0.457924  Outer  \n",
       "3424  0.148617  0.160313  0.148617  0.118726  0.087535  0.069341  Outer  \n",
       "3425  0.081037  0.190204  0.269481  0.281177  0.257784  0.225294  Outer  \n",
       "3426  0.164212  0.172010  0.135621  0.068041  0.005660 -0.058021  Outer  \n",
       "\n",
       "[5 rows x 4097 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g9hLbUef83Jf",
    "outputId": "9baf24f6-d162-43d1-d46b-0761c1242c87"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (3427, 4096)\n",
      "Y shape: (3427,)\n"
     ]
    }
   ],
   "source": [
    "# Separate input features (X) and target labels (Y)\n",
    "X = df.iloc[:, :4096].values  # First 4096 columns contain signal data\n",
    "Y = df['Label'].values        # Last column contains the class labels\n",
    "\n",
    "# Print the shapes to verify the datas\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"Y shape:\", Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 253
    },
    "id": "zdCXO1O0OZCN",
    "outputId": "da8d6d00-5a8b-46c7-fe50-3714b6d1eb0a"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "dataframe",
       "variable_name": "df2"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-0bfe49e8-adc7-4bf9-92aa-5c469ddddce9\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>4086</th>\n",
       "      <th>4087</th>\n",
       "      <th>4088</th>\n",
       "      <th>4089</th>\n",
       "      <th>4090</th>\n",
       "      <th>4091</th>\n",
       "      <th>4092</th>\n",
       "      <th>4093</th>\n",
       "      <th>4094</th>\n",
       "      <th>4095</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.036611e+07</td>\n",
       "      <td>1.938651e+07</td>\n",
       "      <td>2.219876e+07</td>\n",
       "      <td>1.174570e+07</td>\n",
       "      <td>4.331845e+06</td>\n",
       "      <td>1.765021e+07</td>\n",
       "      <td>2.141755e+07</td>\n",
       "      <td>1.807470e+07</td>\n",
       "      <td>1.499715e+07</td>\n",
       "      <td>1.584613e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>3.319714e+07</td>\n",
       "      <td>4.014816e+07</td>\n",
       "      <td>2.842163e+07</td>\n",
       "      <td>1.611143e+07</td>\n",
       "      <td>3.482866e+06</td>\n",
       "      <td>9.517128e+06</td>\n",
       "      <td>2.336610e+07</td>\n",
       "      <td>3.631304e+07</td>\n",
       "      <td>3.970895e+07</td>\n",
       "      <td>3.413753e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.354978e+07</td>\n",
       "      <td>1.122980e+07</td>\n",
       "      <td>2.592775e+07</td>\n",
       "      <td>2.757265e+07</td>\n",
       "      <td>1.409511e+07</td>\n",
       "      <td>1.664070e+06</td>\n",
       "      <td>1.583141e+07</td>\n",
       "      <td>2.633753e+07</td>\n",
       "      <td>3.482732e+07</td>\n",
       "      <td>4.241507e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>2.740009e+06</td>\n",
       "      <td>1.956041e+07</td>\n",
       "      <td>3.839714e+07</td>\n",
       "      <td>5.049509e+07</td>\n",
       "      <td>5.256448e+07</td>\n",
       "      <td>3.898081e+07</td>\n",
       "      <td>2.348694e+07</td>\n",
       "      <td>1.054001e+07</td>\n",
       "      <td>3.415090e+06</td>\n",
       "      <td>1.487631e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.623141e+07</td>\n",
       "      <td>2.936202e+07</td>\n",
       "      <td>1.949263e+07</td>\n",
       "      <td>1.451826e+06</td>\n",
       "      <td>1.743796e+07</td>\n",
       "      <td>2.651143e+07</td>\n",
       "      <td>2.529102e+07</td>\n",
       "      <td>1.658898e+07</td>\n",
       "      <td>5.605314e+06</td>\n",
       "      <td>6.015089e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>1.365590e+07</td>\n",
       "      <td>2.283549e+07</td>\n",
       "      <td>3.031712e+07</td>\n",
       "      <td>3.254569e+07</td>\n",
       "      <td>2.628447e+07</td>\n",
       "      <td>1.423958e+07</td>\n",
       "      <td>2.778356e+06</td>\n",
       "      <td>4.583776e+05</td>\n",
       "      <td>1.625724e+06</td>\n",
       "      <td>4.437968e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.756335e+06</td>\n",
       "      <td>2.103275e+06</td>\n",
       "      <td>8.402843e+06</td>\n",
       "      <td>1.572529e+07</td>\n",
       "      <td>1.837835e+07</td>\n",
       "      <td>9.251822e+06</td>\n",
       "      <td>9.691027e+06</td>\n",
       "      <td>2.062163e+07</td>\n",
       "      <td>2.428286e+07</td>\n",
       "      <td>1.902980e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>5.006926e+06</td>\n",
       "      <td>3.521213e+06</td>\n",
       "      <td>2.566111e+06</td>\n",
       "      <td>5.749783e+06</td>\n",
       "      <td>1.689264e+07</td>\n",
       "      <td>2.188039e+07</td>\n",
       "      <td>1.280692e+07</td>\n",
       "      <td>1.360418e+06</td>\n",
       "      <td>1.314000e+07</td>\n",
       "      <td>1.340531e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.091028e+06</td>\n",
       "      <td>2.686948e+06</td>\n",
       "      <td>7.089688e+05</td>\n",
       "      <td>1.770193e+06</td>\n",
       "      <td>7.235497e+06</td>\n",
       "      <td>2.219876e+07</td>\n",
       "      <td>3.350079e+07</td>\n",
       "      <td>2.766406e+07</td>\n",
       "      <td>1.036611e+07</td>\n",
       "      <td>6.772661e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>6.545701e+06</td>\n",
       "      <td>1.498243e+07</td>\n",
       "      <td>1.874978e+07</td>\n",
       "      <td>1.620284e+07</td>\n",
       "      <td>4.688559e+06</td>\n",
       "      <td>4.597151e+06</td>\n",
       "      <td>1.080397e+06</td>\n",
       "      <td>6.651823e+06</td>\n",
       "      <td>9.570190e+06</td>\n",
       "      <td>7.766109e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 4096 columns</p>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0bfe49e8-adc7-4bf9-92aa-5c469ddddce9')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-0bfe49e8-adc7-4bf9-92aa-5c469ddddce9 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-0bfe49e8-adc7-4bf9-92aa-5c469ddddce9');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    <div id=\"df-aa1b3a05-b69c-401b-bc44-fe4e179fa74f\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-aa1b3a05-b69c-401b-bc44-fe4e179fa74f')\"\n",
       "                title=\"Suggest charts\"\n",
       "                style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "      <script>\n",
       "        async function quickchart(key) {\n",
       "          const quickchartButtonEl =\n",
       "            document.querySelector('#' + key + ' button');\n",
       "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "          try {\n",
       "            const charts = await google.colab.kernel.invokeFunction(\n",
       "                'suggestCharts', [key], {});\n",
       "          } catch (error) {\n",
       "            console.error('Error during call to suggestCharts:', error);\n",
       "          }\n",
       "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "        }\n",
       "        (() => {\n",
       "          let quickchartButtonEl =\n",
       "            document.querySelector('#df-aa1b3a05-b69c-401b-bc44-fe4e179fa74f button');\n",
       "          quickchartButtonEl.style.display =\n",
       "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "        })();\n",
       "      </script>\n",
       "    </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "           0             1             2             3             4     \\\n",
       "0  1.036611e+07  1.938651e+07  2.219876e+07  1.174570e+07  4.331845e+06   \n",
       "1  1.354978e+07  1.122980e+07  2.592775e+07  2.757265e+07  1.409511e+07   \n",
       "2  2.623141e+07  2.936202e+07  1.949263e+07  1.451826e+06  1.743796e+07   \n",
       "3  4.756335e+06  2.103275e+06  8.402843e+06  1.572529e+07  1.837835e+07   \n",
       "4  7.091028e+06  2.686948e+06  7.089688e+05  1.770193e+06  7.235497e+06   \n",
       "\n",
       "           5             6             7             8             9     ...  \\\n",
       "0  1.765021e+07  2.141755e+07  1.807470e+07  1.499715e+07  1.584613e+07  ...   \n",
       "1  1.664070e+06  1.583141e+07  2.633753e+07  3.482732e+07  4.241507e+07  ...   \n",
       "2  2.651143e+07  2.529102e+07  1.658898e+07  5.605314e+06  6.015089e+06  ...   \n",
       "3  9.251822e+06  9.691027e+06  2.062163e+07  2.428286e+07  1.902980e+07  ...   \n",
       "4  2.219876e+07  3.350079e+07  2.766406e+07  1.036611e+07  6.772661e+06  ...   \n",
       "\n",
       "           4086          4087          4088          4089          4090  \\\n",
       "0  3.319714e+07  4.014816e+07  2.842163e+07  1.611143e+07  3.482866e+06   \n",
       "1  2.740009e+06  1.956041e+07  3.839714e+07  5.049509e+07  5.256448e+07   \n",
       "2  1.365590e+07  2.283549e+07  3.031712e+07  3.254569e+07  2.628447e+07   \n",
       "3  5.006926e+06  3.521213e+06  2.566111e+06  5.749783e+06  1.689264e+07   \n",
       "4  6.545701e+06  1.498243e+07  1.874978e+07  1.620284e+07  4.688559e+06   \n",
       "\n",
       "           4091          4092          4093          4094          4095  \n",
       "0  9.517128e+06  2.336610e+07  3.631304e+07  3.970895e+07  3.413753e+07  \n",
       "1  3.898081e+07  2.348694e+07  1.054001e+07  3.415090e+06  1.487631e+07  \n",
       "2  1.423958e+07  2.778356e+06  4.583776e+05  1.625724e+06  4.437968e+06  \n",
       "3  2.188039e+07  1.280692e+07  1.360418e+06  1.314000e+07  1.340531e+07  \n",
       "4  4.597151e+06  1.080397e+06  6.651823e+06  9.570190e+06  7.766109e+06  \n",
       "\n",
       "[5 rows x 4096 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define sampling frequency and time vector\n",
    "sampling_freq = 24000  # Hz\n",
    "numofsamples = 4096\n",
    "time = np.linspace(0, numofsamples / sampling_freq, numofsamples)\n",
    "\n",
    "# Compute FFT for all samples\n",
    "X = np.abs(np.fft.fft(X))  # Changed: Take magnitude to convert complex to real\n",
    "\n",
    "df2 = pd.DataFrame(X)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9Y29_SaLRdCE",
    "outputId": "842e37b2-0f8b-47d2-d5ca-9d454ba922f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3427 entries, 0 to 3426\n",
      "Columns: 4096 entries, 0 to 4095\n",
      "dtypes: float64(4096)\n",
      "memory usage: 107.1 MB\n"
     ]
    }
   ],
   "source": [
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9Q4I3YM4GHj1",
    "outputId": "1b703601-9f09-4c76-c86f-f0289643b6f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded Y shape: (3427, 4)\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoded_Y = encoder.fit_transform(Y)      # Convert string labels to integer indices\n",
    "OHE_Y = to_categorical(encoded_Y)         # One-hot encode the integer labels\n",
    "\n",
    "# Save the encoder to disk to use it later during inference\n",
    "joblib.dump(encoder, '/content/drive/MyDrive/SAYZEK/beginning/encoder.pkl')\n",
    "\n",
    "# Check the shape of the one-hot encoded labels\n",
    "print(\"Encoded Y shape:\", OHE_Y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qLweea35GV7c",
    "outputId": "29c80935-caf5-464e-ecc2-7df149799064"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (2741, 4096)\n",
      "X_test shape: (686, 4096)\n",
      "y_train shape: (2741, 4)\n",
      "y_test shape: (686, 4)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "\n",
    "# Split the data into training and testing sets with stratification\n",
    "X_train, X_test, y_train, y_test = train_test_split(df2, OHE_Y, test_size=0.2, stratify=Y, random_state=42)\n",
    "\n",
    "# Normalize input features (standard scaling)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)  # Fit the scaler only on training data\n",
    "X_test = scaler.transform(X_test)        # Use the same scaler on test data\n",
    "\n",
    "# Save the fitted scaler for future use\n",
    "joblib.dump(scaler, '/content/drive/MyDrive/SAYZEK/beginning/scaler.pkl')\n",
    "\n",
    "# Reshape input data to match Conv1D input requirements: (samples, time_steps, 1 channel)\n",
    "X_train = X_train.reshape(-1, 4096).transpose(0, 1)\n",
    "X_test = X_test.reshape(-1, 4096).transpose(0, 1)\n",
    "\n",
    "# Print dataset shapes\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 599
    },
    "id": "38IyuQ822JXk",
    "outputId": "bf2bfdc5-105a-4b4b-a44e-56cfe8b82ce0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">24,704</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">131072</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │    <span style=\"color: #00af00; text-decoration-color: #00af00\">16,777,344</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">516</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │           \u001b[38;5;34m256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d (\u001b[38;5;33mMaxPooling1D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │        \u001b[38;5;34m24,704\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_1 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m131072\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │    \u001b[38;5;34m16,777,344\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │           \u001b[38;5;34m516\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">16,803,588</span> (64.10 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m16,803,588\u001b[0m (64.10 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">16,803,204</span> (64.10 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m16,803,204\u001b[0m (64.10 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> (1.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m384\u001b[0m (1.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# First 1D Convolutional Layer with 64 filters and ReLU activation\n",
    "model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(4096,1), padding='same'))\n",
    "model.add(BatchNormalization())          # Normalize activations\n",
    "model.add(MaxPooling1D(pool_size=2))     # Downsample by factor of 2\n",
    "model.add(Dropout(0.3))                  # Dropout to prevent overfitting\n",
    "\n",
    "# Second 1D Convolutional Layer with 128 filters\n",
    "model.add(Conv1D(filters=128, kernel_size=3, activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "# Flatten the output for the fully connected layers\n",
    "model.add(Flatten())\n",
    "\n",
    "# Fully connected layer with ReLU activation\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))  # Dropout before final output layer\n",
    "\n",
    "# Output layer with softmax activation for multi-class classification\n",
    "model.add(Dense(len(encoder.classes_), activation='softmax'))\n",
    "\n",
    "# Compile the model with Adam optimizer and categorical crossentropy loss\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Show the model architecture\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nw8JKc1M-jxO",
    "outputId": "39c1e12d-2ac9-4b2b-88bc-03d2860ee9b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 331ms/step - accuracy: 0.4771 - loss: 8.7429 - val_accuracy: 0.2230 - val_loss: 12.4083\n",
      "Epoch 2/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - accuracy: 0.5540 - loss: 0.9601 - val_accuracy: 0.1633 - val_loss: 23.7846\n",
      "Epoch 3/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - accuracy: 0.6758 - loss: 0.7715 - val_accuracy: 0.1531 - val_loss: 33.1648\n",
      "Epoch 4/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - accuracy: 0.6850 - loss: 0.6955 - val_accuracy: 0.1312 - val_loss: 38.7434\n",
      "Epoch 5/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - accuracy: 0.7011 - loss: 0.6184 - val_accuracy: 0.1239 - val_loss: 43.8570\n",
      "Epoch 6/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - accuracy: 0.7396 - loss: 0.5916 - val_accuracy: 0.1166 - val_loss: 48.6131\n",
      "Epoch 7/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - accuracy: 0.7693 - loss: 0.5756 - val_accuracy: 0.1399 - val_loss: 49.3776\n",
      "Epoch 8/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - accuracy: 0.7684 - loss: 0.4905 - val_accuracy: 0.1808 - val_loss: 53.2577\n",
      "Epoch 9/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - accuracy: 0.7662 - loss: 0.4843 - val_accuracy: 0.2128 - val_loss: 57.8563\n",
      "Epoch 10/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - accuracy: 0.7690 - loss: 0.4503 - val_accuracy: 0.2595 - val_loss: 50.5698\n",
      "Epoch 11/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - accuracy: 0.7722 - loss: 0.4291 - val_accuracy: 0.2143 - val_loss: 46.3868\n",
      "Epoch 12/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - accuracy: 0.8070 - loss: 0.3949 - val_accuracy: 0.2478 - val_loss: 47.4390\n",
      "Epoch 13/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - accuracy: 0.8020 - loss: 0.4083 - val_accuracy: 0.3076 - val_loss: 49.5148\n",
      "Epoch 14/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - accuracy: 0.8169 - loss: 0.3826 - val_accuracy: 0.3032 - val_loss: 46.3394\n",
      "Epoch 15/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - accuracy: 0.8423 - loss: 0.3560 - val_accuracy: 0.2434 - val_loss: 48.9113\n",
      "Epoch 16/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - accuracy: 0.8372 - loss: 0.3513 - val_accuracy: 0.2813 - val_loss: 52.3055\n",
      "Epoch 17/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - accuracy: 0.8500 - loss: 0.3478 - val_accuracy: 0.2988 - val_loss: 53.6336\n",
      "Epoch 18/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - accuracy: 0.8498 - loss: 0.3708 - val_accuracy: 0.2959 - val_loss: 48.7716\n",
      "Epoch 19/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - accuracy: 0.8562 - loss: 0.3160 - val_accuracy: 0.2959 - val_loss: 43.9711\n",
      "Epoch 20/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - accuracy: 0.8712 - loss: 0.3114 - val_accuracy: 0.3294 - val_loss: 31.2004\n",
      "Epoch 21/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - accuracy: 0.8682 - loss: 0.3048 - val_accuracy: 0.3746 - val_loss: 31.9109\n",
      "Epoch 22/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - accuracy: 0.8865 - loss: 0.3049 - val_accuracy: 0.3834 - val_loss: 26.9215\n",
      "Epoch 23/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - accuracy: 0.8738 - loss: 0.3393 - val_accuracy: 0.4155 - val_loss: 22.4397\n",
      "Epoch 24/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.8943 - loss: 0.2928 - val_accuracy: 0.5190 - val_loss: 16.7687\n",
      "Epoch 25/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.8901 - loss: 0.2931 - val_accuracy: 0.4985 - val_loss: 16.6410\n",
      "Epoch 26/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - accuracy: 0.9031 - loss: 0.2337 - val_accuracy: 0.5335 - val_loss: 13.7348\n",
      "Epoch 27/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - accuracy: 0.8839 - loss: 0.2866 - val_accuracy: 0.5496 - val_loss: 13.5981\n",
      "Epoch 28/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.8649 - loss: 0.2982 - val_accuracy: 0.5962 - val_loss: 12.8403\n",
      "Epoch 29/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.8989 - loss: 0.2449 - val_accuracy: 0.7216 - val_loss: 6.1206\n",
      "Epoch 30/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9015 - loss: 0.2546 - val_accuracy: 0.7245 - val_loss: 5.0403\n",
      "Epoch 31/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.8972 - loss: 0.2468 - val_accuracy: 0.7376 - val_loss: 4.2622\n",
      "Epoch 32/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9015 - loss: 0.2551 - val_accuracy: 0.7434 - val_loss: 4.2257\n",
      "Epoch 33/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9121 - loss: 0.2183 - val_accuracy: 0.7536 - val_loss: 3.8169\n",
      "Epoch 34/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9248 - loss: 0.2039 - val_accuracy: 0.7799 - val_loss: 3.8483\n",
      "Epoch 35/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9231 - loss: 0.2133 - val_accuracy: 0.7828 - val_loss: 2.5322\n",
      "Epoch 36/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - accuracy: 0.9042 - loss: 0.2190 - val_accuracy: 0.7784 - val_loss: 2.4084\n",
      "Epoch 37/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9184 - loss: 0.2208 - val_accuracy: 0.7522 - val_loss: 3.5006\n",
      "Epoch 38/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9085 - loss: 0.2344 - val_accuracy: 0.7566 - val_loss: 2.8074\n",
      "Epoch 39/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - accuracy: 0.9338 - loss: 0.1800 - val_accuracy: 0.7653 - val_loss: 2.1911\n",
      "Epoch 40/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - accuracy: 0.9184 - loss: 0.2304 - val_accuracy: 0.7799 - val_loss: 1.8159\n",
      "Epoch 41/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - accuracy: 0.9127 - loss: 0.2274 - val_accuracy: 0.8003 - val_loss: 2.0808\n",
      "Epoch 42/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - accuracy: 0.9257 - loss: 0.2156 - val_accuracy: 0.8601 - val_loss: 0.6811\n",
      "Epoch 43/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - accuracy: 0.9338 - loss: 0.1759 - val_accuracy: 0.8644 - val_loss: 0.7803\n",
      "Epoch 44/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - accuracy: 0.9278 - loss: 0.1909 - val_accuracy: 0.8703 - val_loss: 0.8251\n",
      "Epoch 45/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - accuracy: 0.9169 - loss: 0.2123 - val_accuracy: 0.8367 - val_loss: 1.0366\n",
      "Epoch 46/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - accuracy: 0.9389 - loss: 0.1725 - val_accuracy: 0.8688 - val_loss: 0.7514\n",
      "Epoch 47/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - accuracy: 0.9250 - loss: 0.2173 - val_accuracy: 0.8455 - val_loss: 0.8291\n",
      "Epoch 48/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - accuracy: 0.9324 - loss: 0.1832 - val_accuracy: 0.8265 - val_loss: 1.3729\n",
      "Epoch 49/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9198 - loss: 0.2173 - val_accuracy: 0.8324 - val_loss: 1.2665\n",
      "Epoch 50/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9239 - loss: 0.2224 - val_accuracy: 0.8776 - val_loss: 0.8791\n",
      "Epoch 51/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9337 - loss: 0.1764 - val_accuracy: 0.8717 - val_loss: 0.8904\n",
      "Epoch 52/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - accuracy: 0.9204 - loss: 0.2046 - val_accuracy: 0.8455 - val_loss: 0.9209\n",
      "Epoch 53/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - accuracy: 0.9302 - loss: 0.2001 - val_accuracy: 0.8746 - val_loss: 0.8007\n",
      "Epoch 54/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9342 - loss: 0.1808 - val_accuracy: 0.8644 - val_loss: 0.8513\n",
      "Epoch 55/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9241 - loss: 0.1944 - val_accuracy: 0.8703 - val_loss: 1.0083\n",
      "Epoch 56/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9224 - loss: 0.1906 - val_accuracy: 0.8105 - val_loss: 1.7538\n",
      "Epoch 57/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9273 - loss: 0.1890 - val_accuracy: 0.8134 - val_loss: 1.9593\n",
      "Epoch 58/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9397 - loss: 0.1585 - val_accuracy: 0.8688 - val_loss: 0.8797\n",
      "Epoch 59/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9359 - loss: 0.1698 - val_accuracy: 0.8659 - val_loss: 0.6986\n",
      "Epoch 60/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9339 - loss: 0.1683 - val_accuracy: 0.8732 - val_loss: 0.8906\n",
      "Epoch 61/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9392 - loss: 0.1601 - val_accuracy: 0.8484 - val_loss: 1.1698\n",
      "Epoch 62/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9535 - loss: 0.1540 - val_accuracy: 0.8265 - val_loss: 2.4335\n",
      "Epoch 63/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - accuracy: 0.9331 - loss: 0.1643 - val_accuracy: 0.8761 - val_loss: 0.9022\n",
      "Epoch 64/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9459 - loss: 0.1765 - val_accuracy: 0.8586 - val_loss: 0.8457\n",
      "Epoch 65/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9369 - loss: 0.1669 - val_accuracy: 0.8615 - val_loss: 0.7522\n",
      "Epoch 66/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9355 - loss: 0.1595 - val_accuracy: 0.8878 - val_loss: 0.5926\n",
      "Epoch 67/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9484 - loss: 0.1444 - val_accuracy: 0.8659 - val_loss: 0.8861\n",
      "Epoch 68/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9423 - loss: 0.1501 - val_accuracy: 0.8994 - val_loss: 0.4685\n",
      "Epoch 69/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9389 - loss: 0.1455 - val_accuracy: 0.8921 - val_loss: 0.5793\n",
      "Epoch 70/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9416 - loss: 0.1625 - val_accuracy: 0.8703 - val_loss: 0.7372\n",
      "Epoch 71/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9449 - loss: 0.1512 - val_accuracy: 0.8338 - val_loss: 1.2333\n",
      "Epoch 72/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - accuracy: 0.9510 - loss: 0.1383 - val_accuracy: 0.8863 - val_loss: 0.7873\n",
      "Epoch 73/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9510 - loss: 0.1408 - val_accuracy: 0.8703 - val_loss: 0.7961\n",
      "Epoch 74/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9504 - loss: 0.1444 - val_accuracy: 0.8571 - val_loss: 1.3451\n",
      "Epoch 75/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9460 - loss: 0.1519 - val_accuracy: 0.8703 - val_loss: 0.9148\n",
      "Epoch 76/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9513 - loss: 0.1358 - val_accuracy: 0.8907 - val_loss: 0.6725\n",
      "Epoch 77/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9584 - loss: 0.1224 - val_accuracy: 0.8892 - val_loss: 0.6302\n",
      "Epoch 78/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9508 - loss: 0.1408 - val_accuracy: 0.8819 - val_loss: 0.7024\n",
      "Epoch 79/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9528 - loss: 0.1381 - val_accuracy: 0.8980 - val_loss: 0.6212\n",
      "Epoch 80/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9544 - loss: 0.1352 - val_accuracy: 0.8878 - val_loss: 0.6834\n",
      "Epoch 81/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9562 - loss: 0.1324 - val_accuracy: 0.8440 - val_loss: 1.8060\n",
      "Epoch 82/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9454 - loss: 0.1596 - val_accuracy: 0.8615 - val_loss: 1.2580\n",
      "Epoch 83/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - accuracy: 0.9503 - loss: 0.1385 - val_accuracy: 0.8499 - val_loss: 1.0718\n",
      "Epoch 84/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9467 - loss: 0.1592 - val_accuracy: 0.8980 - val_loss: 0.5395\n",
      "Epoch 85/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9488 - loss: 0.1476 - val_accuracy: 0.8892 - val_loss: 0.5416\n",
      "Epoch 86/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9555 - loss: 0.1387 - val_accuracy: 0.9052 - val_loss: 0.8649\n",
      "Epoch 87/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9488 - loss: 0.1433 - val_accuracy: 0.8907 - val_loss: 0.6521\n",
      "Epoch 88/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9501 - loss: 0.1458 - val_accuracy: 0.8746 - val_loss: 0.8632\n",
      "Epoch 89/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9579 - loss: 0.1241 - val_accuracy: 0.8805 - val_loss: 0.7143\n",
      "Epoch 90/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9500 - loss: 0.1377 - val_accuracy: 0.8980 - val_loss: 0.6875\n",
      "Epoch 91/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9550 - loss: 0.1351 - val_accuracy: 0.8950 - val_loss: 0.5639\n",
      "Epoch 92/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - accuracy: 0.9478 - loss: 0.1393 - val_accuracy: 0.8586 - val_loss: 1.9279\n",
      "Epoch 93/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9371 - loss: 0.1581 - val_accuracy: 0.8950 - val_loss: 0.5902\n",
      "Epoch 94/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9492 - loss: 0.1451 - val_accuracy: 0.8907 - val_loss: 0.6190\n",
      "Epoch 95/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9470 - loss: 0.1484 - val_accuracy: 0.8921 - val_loss: 0.7595\n",
      "Epoch 96/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9557 - loss: 0.1231 - val_accuracy: 0.8499 - val_loss: 1.1110\n",
      "Epoch 97/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9586 - loss: 0.1208 - val_accuracy: 0.8615 - val_loss: 1.2285\n",
      "Epoch 98/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9550 - loss: 0.1264 - val_accuracy: 0.8615 - val_loss: 0.7719\n",
      "Epoch 99/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9503 - loss: 0.2006 - val_accuracy: 0.8659 - val_loss: 1.0715\n",
      "Epoch 100/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9483 - loss: 0.1283 - val_accuracy: 0.8980 - val_loss: 0.5276\n",
      "Epoch 101/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9640 - loss: 0.1022 - val_accuracy: 0.8965 - val_loss: 0.6115\n",
      "Epoch 102/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9537 - loss: 0.1286 - val_accuracy: 0.9198 - val_loss: 0.5459\n",
      "Epoch 103/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - accuracy: 0.9622 - loss: 0.1149 - val_accuracy: 0.8761 - val_loss: 0.9841\n",
      "Epoch 104/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9555 - loss: 0.1456 - val_accuracy: 0.9125 - val_loss: 0.6241\n",
      "Epoch 105/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9517 - loss: 0.1378 - val_accuracy: 0.8863 - val_loss: 0.7840\n",
      "Epoch 106/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9614 - loss: 0.1140 - val_accuracy: 0.8994 - val_loss: 0.7713\n",
      "Epoch 107/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9644 - loss: 0.1152 - val_accuracy: 0.8746 - val_loss: 0.8826\n",
      "Epoch 108/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - accuracy: 0.9534 - loss: 0.1251 - val_accuracy: 0.8776 - val_loss: 0.9302\n",
      "Epoch 109/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9548 - loss: 0.1238 - val_accuracy: 0.8673 - val_loss: 1.0560\n",
      "Epoch 110/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9632 - loss: 0.1255 - val_accuracy: 0.8280 - val_loss: 2.9791\n",
      "Epoch 111/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9552 - loss: 0.1311 - val_accuracy: 0.9038 - val_loss: 0.4914\n",
      "Epoch 112/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9593 - loss: 0.1196 - val_accuracy: 0.8499 - val_loss: 1.7277\n",
      "Epoch 113/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9533 - loss: 0.1399 - val_accuracy: 0.7711 - val_loss: 3.1944\n",
      "Epoch 114/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9610 - loss: 0.1636 - val_accuracy: 0.8134 - val_loss: 2.3965\n",
      "Epoch 115/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9561 - loss: 0.1283 - val_accuracy: 0.8032 - val_loss: 2.1815\n",
      "Epoch 116/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9669 - loss: 0.1212 - val_accuracy: 0.8615 - val_loss: 1.2236\n",
      "Epoch 117/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9586 - loss: 0.1315 - val_accuracy: 0.8746 - val_loss: 0.7134\n",
      "Epoch 118/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9527 - loss: 0.1216 - val_accuracy: 0.8673 - val_loss: 0.9303\n",
      "Epoch 119/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9572 - loss: 0.1259 - val_accuracy: 0.8571 - val_loss: 1.1571\n",
      "Epoch 120/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - accuracy: 0.9595 - loss: 0.1065 - val_accuracy: 0.8907 - val_loss: 0.8173\n",
      "Epoch 121/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9571 - loss: 0.1195 - val_accuracy: 0.8848 - val_loss: 0.8310\n",
      "Epoch 122/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9579 - loss: 0.1361 - val_accuracy: 0.8659 - val_loss: 0.9688\n",
      "Epoch 123/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9696 - loss: 0.0971 - val_accuracy: 0.8673 - val_loss: 1.0847\n",
      "Epoch 124/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9561 - loss: 0.1293 - val_accuracy: 0.8834 - val_loss: 0.7440\n",
      "Epoch 125/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9558 - loss: 0.1206 - val_accuracy: 0.8834 - val_loss: 0.8602\n",
      "Epoch 126/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9598 - loss: 0.1192 - val_accuracy: 0.8936 - val_loss: 0.5145\n",
      "Epoch 127/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - accuracy: 0.9621 - loss: 0.1102 - val_accuracy: 0.8513 - val_loss: 0.9886\n",
      "Epoch 128/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - accuracy: 0.9651 - loss: 0.1011 - val_accuracy: 0.8848 - val_loss: 0.5714\n",
      "Epoch 129/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - accuracy: 0.9612 - loss: 0.1231 - val_accuracy: 0.8717 - val_loss: 0.6721\n",
      "Epoch 130/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - accuracy: 0.9600 - loss: 0.1092 - val_accuracy: 0.8834 - val_loss: 0.6402\n",
      "Epoch 131/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - accuracy: 0.9714 - loss: 0.0849 - val_accuracy: 0.9023 - val_loss: 0.5122\n",
      "Epoch 132/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9613 - loss: 0.0966 - val_accuracy: 0.8921 - val_loss: 0.8093\n",
      "Epoch 133/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9684 - loss: 0.0892 - val_accuracy: 0.8950 - val_loss: 0.6177\n",
      "Epoch 134/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9649 - loss: 0.0997 - val_accuracy: 0.8936 - val_loss: 0.6413\n",
      "Epoch 135/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9672 - loss: 0.0984 - val_accuracy: 0.8878 - val_loss: 0.6721\n",
      "Epoch 136/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - accuracy: 0.9630 - loss: 0.0990 - val_accuracy: 0.8659 - val_loss: 1.0582\n",
      "Epoch 137/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9681 - loss: 0.0899 - val_accuracy: 0.9111 - val_loss: 0.6078\n",
      "Epoch 138/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9555 - loss: 0.1119 - val_accuracy: 0.9038 - val_loss: 0.4665\n",
      "Epoch 139/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9698 - loss: 0.0876 - val_accuracy: 0.8673 - val_loss: 1.2105\n",
      "Epoch 140/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9674 - loss: 0.0983 - val_accuracy: 0.8950 - val_loss: 0.6587\n",
      "Epoch 141/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - accuracy: 0.9700 - loss: 0.0877 - val_accuracy: 0.9257 - val_loss: 0.3415\n",
      "Epoch 142/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9662 - loss: 0.1183 - val_accuracy: 0.8805 - val_loss: 0.7819\n",
      "Epoch 143/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9637 - loss: 0.0948 - val_accuracy: 0.9286 - val_loss: 0.3310\n",
      "Epoch 144/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9653 - loss: 0.1076 - val_accuracy: 0.8411 - val_loss: 1.6076\n",
      "Epoch 145/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9643 - loss: 0.1163 - val_accuracy: 0.8980 - val_loss: 0.7376\n",
      "Epoch 146/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9605 - loss: 0.1066 - val_accuracy: 0.8673 - val_loss: 1.1460\n",
      "Epoch 147/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - accuracy: 0.9654 - loss: 0.1036 - val_accuracy: 0.8703 - val_loss: 1.1868\n",
      "Epoch 148/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - accuracy: 0.9713 - loss: 0.0845 - val_accuracy: 0.9023 - val_loss: 0.7040\n",
      "Epoch 149/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9733 - loss: 0.0857 - val_accuracy: 0.9023 - val_loss: 0.6208\n",
      "Epoch 150/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9574 - loss: 0.1295 - val_accuracy: 0.9242 - val_loss: 0.3495\n",
      "Epoch 151/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9652 - loss: 0.0931 - val_accuracy: 0.9111 - val_loss: 0.5012\n",
      "Epoch 152/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9750 - loss: 0.0787 - val_accuracy: 0.8469 - val_loss: 1.4900\n",
      "Epoch 153/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - accuracy: 0.9638 - loss: 0.1128 - val_accuracy: 0.8892 - val_loss: 0.7742\n",
      "Epoch 154/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9664 - loss: 0.0941 - val_accuracy: 0.9082 - val_loss: 0.4830\n",
      "Epoch 155/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9608 - loss: 0.1018 - val_accuracy: 0.8994 - val_loss: 0.8774\n",
      "Epoch 156/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9613 - loss: 0.1040 - val_accuracy: 0.8805 - val_loss: 0.8194\n",
      "Epoch 157/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9738 - loss: 0.0739 - val_accuracy: 0.8980 - val_loss: 0.8892\n",
      "Epoch 158/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9670 - loss: 0.1119 - val_accuracy: 0.8294 - val_loss: 1.9641\n",
      "Epoch 159/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - accuracy: 0.9654 - loss: 0.1291 - val_accuracy: 0.9023 - val_loss: 0.5633\n",
      "Epoch 160/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9718 - loss: 0.0858 - val_accuracy: 0.9096 - val_loss: 0.4934\n",
      "Epoch 161/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9729 - loss: 0.0892 - val_accuracy: 0.8761 - val_loss: 1.0180\n",
      "Epoch 162/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9704 - loss: 0.0934 - val_accuracy: 0.8819 - val_loss: 0.9677\n",
      "Epoch 163/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9681 - loss: 0.1073 - val_accuracy: 0.8819 - val_loss: 1.1872\n",
      "Epoch 164/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9711 - loss: 0.1107 - val_accuracy: 0.9096 - val_loss: 0.6658\n",
      "Epoch 165/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9665 - loss: 0.1107 - val_accuracy: 0.9300 - val_loss: 0.3196\n",
      "Epoch 166/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9659 - loss: 0.1023 - val_accuracy: 0.9402 - val_loss: 0.3194\n",
      "Epoch 167/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9704 - loss: 0.0878 - val_accuracy: 0.9227 - val_loss: 0.4078\n",
      "Epoch 168/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9686 - loss: 0.0968 - val_accuracy: 0.9344 - val_loss: 0.4572\n",
      "Epoch 169/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9757 - loss: 0.0847 - val_accuracy: 0.8819 - val_loss: 0.8948\n",
      "Epoch 170/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - accuracy: 0.9704 - loss: 0.0810 - val_accuracy: 0.9140 - val_loss: 0.5644\n",
      "Epoch 171/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9614 - loss: 0.1087 - val_accuracy: 0.9023 - val_loss: 0.8495\n",
      "Epoch 172/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9741 - loss: 0.0866 - val_accuracy: 0.9198 - val_loss: 0.3572\n",
      "Epoch 173/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9720 - loss: 0.0808 - val_accuracy: 0.9373 - val_loss: 0.3194\n",
      "Epoch 174/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9739 - loss: 0.0748 - val_accuracy: 0.9286 - val_loss: 0.4214\n",
      "Epoch 175/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9763 - loss: 0.0732 - val_accuracy: 0.9213 - val_loss: 0.4411\n",
      "Epoch 176/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - accuracy: 0.9737 - loss: 0.0729 - val_accuracy: 0.9315 - val_loss: 0.4043\n",
      "Epoch 177/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9722 - loss: 0.0758 - val_accuracy: 0.9242 - val_loss: 0.4537\n",
      "Epoch 178/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9736 - loss: 0.0801 - val_accuracy: 0.9213 - val_loss: 0.5215\n",
      "Epoch 179/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9706 - loss: 0.0898 - val_accuracy: 0.9300 - val_loss: 0.4219\n",
      "Epoch 180/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9767 - loss: 0.0676 - val_accuracy: 0.8892 - val_loss: 1.0113\n",
      "Epoch 181/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9732 - loss: 0.0868 - val_accuracy: 0.9257 - val_loss: 0.4426\n",
      "Epoch 182/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - accuracy: 0.9763 - loss: 0.0676 - val_accuracy: 0.9096 - val_loss: 0.5279\n",
      "Epoch 183/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9720 - loss: 0.0748 - val_accuracy: 0.9125 - val_loss: 0.5454\n",
      "Epoch 184/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9731 - loss: 0.0837 - val_accuracy: 0.8921 - val_loss: 0.9262\n",
      "Epoch 185/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9741 - loss: 0.0756 - val_accuracy: 0.8367 - val_loss: 1.7660\n",
      "Epoch 186/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9698 - loss: 0.0913 - val_accuracy: 0.9096 - val_loss: 0.5396\n",
      "Epoch 187/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9751 - loss: 0.0928 - val_accuracy: 0.9198 - val_loss: 0.5198\n",
      "Epoch 188/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9757 - loss: 0.0721 - val_accuracy: 0.9052 - val_loss: 0.5678\n",
      "Epoch 189/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9788 - loss: 0.0661 - val_accuracy: 0.9111 - val_loss: 0.5570\n",
      "Epoch 190/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9748 - loss: 0.0762 - val_accuracy: 0.8834 - val_loss: 0.8005\n",
      "Epoch 191/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9718 - loss: 0.1257 - val_accuracy: 0.9082 - val_loss: 0.6289\n",
      "Epoch 192/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9725 - loss: 0.0806 - val_accuracy: 0.8557 - val_loss: 1.0675\n",
      "Epoch 193/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9678 - loss: 0.1041 - val_accuracy: 0.8848 - val_loss: 0.7544\n",
      "Epoch 194/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9729 - loss: 0.0922 - val_accuracy: 0.8717 - val_loss: 1.2553\n",
      "Epoch 195/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9692 - loss: 0.0916 - val_accuracy: 0.8994 - val_loss: 1.0577\n",
      "Epoch 196/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9738 - loss: 0.0922 - val_accuracy: 0.9271 - val_loss: 0.3268\n",
      "Epoch 197/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9777 - loss: 0.0676 - val_accuracy: 0.9111 - val_loss: 0.6472\n",
      "Epoch 198/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9744 - loss: 0.0737 - val_accuracy: 0.9140 - val_loss: 0.6769\n",
      "Epoch 199/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9835 - loss: 0.0773 - val_accuracy: 0.8936 - val_loss: 0.8129\n",
      "Epoch 200/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9749 - loss: 0.0825 - val_accuracy: 0.8630 - val_loss: 1.6516\n",
      "Epoch 201/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9725 - loss: 0.0778 - val_accuracy: 0.9067 - val_loss: 0.4742\n",
      "Epoch 202/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9577 - loss: 0.1024 - val_accuracy: 0.8907 - val_loss: 0.7197\n",
      "Epoch 203/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9774 - loss: 0.0599 - val_accuracy: 0.9315 - val_loss: 0.5587\n",
      "Epoch 204/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9804 - loss: 0.0751 - val_accuracy: 0.9125 - val_loss: 0.7572\n",
      "Epoch 205/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9772 - loss: 0.0724 - val_accuracy: 0.9038 - val_loss: 0.7457\n",
      "Epoch 206/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9778 - loss: 0.0719 - val_accuracy: 0.8965 - val_loss: 0.8512\n",
      "Epoch 207/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9794 - loss: 0.0657 - val_accuracy: 0.9038 - val_loss: 0.8604\n",
      "Epoch 208/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9784 - loss: 0.0633 - val_accuracy: 0.9125 - val_loss: 0.6480\n",
      "Epoch 209/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9766 - loss: 0.0657 - val_accuracy: 0.9096 - val_loss: 0.6091\n",
      "Epoch 210/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9805 - loss: 0.0541 - val_accuracy: 0.9213 - val_loss: 0.5806\n",
      "Epoch 211/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9783 - loss: 0.0916 - val_accuracy: 0.8848 - val_loss: 0.8262\n",
      "Epoch 212/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - accuracy: 0.9765 - loss: 0.0970 - val_accuracy: 0.8834 - val_loss: 0.8364\n",
      "Epoch 213/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9734 - loss: 0.0761 - val_accuracy: 0.8848 - val_loss: 0.9595\n",
      "Epoch 214/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9747 - loss: 0.0748 - val_accuracy: 0.8761 - val_loss: 1.2650\n",
      "Epoch 215/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9751 - loss: 0.0728 - val_accuracy: 0.8950 - val_loss: 0.8530\n",
      "Epoch 216/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9758 - loss: 0.0801 - val_accuracy: 0.9140 - val_loss: 0.7837\n",
      "Epoch 217/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9714 - loss: 0.0850 - val_accuracy: 0.9082 - val_loss: 0.7648\n",
      "Epoch 218/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9753 - loss: 0.0719 - val_accuracy: 0.9242 - val_loss: 0.4932\n",
      "Epoch 219/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9772 - loss: 0.0664 - val_accuracy: 0.8921 - val_loss: 0.9686\n",
      "Epoch 220/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9810 - loss: 0.0554 - val_accuracy: 0.9023 - val_loss: 0.8727\n",
      "Epoch 221/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9796 - loss: 0.0724 - val_accuracy: 0.9140 - val_loss: 0.6047\n",
      "Epoch 222/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9788 - loss: 0.0576 - val_accuracy: 0.9155 - val_loss: 0.6669\n",
      "Epoch 223/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9776 - loss: 0.0743 - val_accuracy: 0.8863 - val_loss: 0.9904\n",
      "Epoch 224/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9778 - loss: 0.0669 - val_accuracy: 0.9009 - val_loss: 1.1673\n",
      "Epoch 225/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9776 - loss: 0.0619 - val_accuracy: 0.8980 - val_loss: 0.6070\n",
      "Epoch 226/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9782 - loss: 0.0596 - val_accuracy: 0.9300 - val_loss: 0.3869\n",
      "Epoch 227/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9793 - loss: 0.0812 - val_accuracy: 0.7799 - val_loss: 6.7169\n",
      "Epoch 228/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9697 - loss: 0.2389 - val_accuracy: 0.8571 - val_loss: 0.9650\n",
      "Epoch 229/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9654 - loss: 0.1622 - val_accuracy: 0.8499 - val_loss: 0.7578\n",
      "Epoch 230/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9669 - loss: 0.1191 - val_accuracy: 0.8950 - val_loss: 0.5529\n",
      "Epoch 231/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9709 - loss: 0.0793 - val_accuracy: 0.8965 - val_loss: 0.6359\n",
      "Epoch 232/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9776 - loss: 0.0636 - val_accuracy: 0.9023 - val_loss: 0.7483\n",
      "Epoch 233/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9783 - loss: 0.0688 - val_accuracy: 0.9023 - val_loss: 0.7525\n",
      "Epoch 234/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9707 - loss: 0.0768 - val_accuracy: 0.8863 - val_loss: 1.0881\n",
      "Epoch 235/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9755 - loss: 0.0650 - val_accuracy: 0.8761 - val_loss: 1.2592\n",
      "Epoch 236/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9797 - loss: 0.0616 - val_accuracy: 0.8965 - val_loss: 1.0141\n",
      "Epoch 237/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9858 - loss: 0.0481 - val_accuracy: 0.9184 - val_loss: 0.6247\n",
      "Epoch 238/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9768 - loss: 0.0731 - val_accuracy: 0.8921 - val_loss: 1.0483\n",
      "Epoch 239/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9790 - loss: 0.0648 - val_accuracy: 0.8805 - val_loss: 1.1775\n",
      "Epoch 240/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9740 - loss: 0.0738 - val_accuracy: 0.8834 - val_loss: 1.3118\n",
      "Epoch 241/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9793 - loss: 0.0662 - val_accuracy: 0.8819 - val_loss: 1.2340\n",
      "Epoch 242/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9786 - loss: 0.0732 - val_accuracy: 0.8980 - val_loss: 0.6796\n",
      "Epoch 243/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9733 - loss: 0.0774 - val_accuracy: 0.9111 - val_loss: 0.5150\n",
      "Epoch 244/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9747 - loss: 0.0727 - val_accuracy: 0.9067 - val_loss: 0.8240\n",
      "Epoch 245/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9775 - loss: 0.1225 - val_accuracy: 0.8863 - val_loss: 1.3285\n",
      "Epoch 246/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9802 - loss: 0.0685 - val_accuracy: 0.9184 - val_loss: 0.4542\n",
      "Epoch 247/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9744 - loss: 0.0869 - val_accuracy: 0.9155 - val_loss: 0.3743\n",
      "Epoch 248/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9701 - loss: 0.0904 - val_accuracy: 0.9169 - val_loss: 0.6940\n",
      "Epoch 249/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9767 - loss: 0.0958 - val_accuracy: 0.9038 - val_loss: 0.7787\n",
      "Epoch 250/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9755 - loss: 0.0677 - val_accuracy: 0.8980 - val_loss: 1.2494\n",
      "Epoch 251/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9797 - loss: 0.1147 - val_accuracy: 0.9096 - val_loss: 0.5937\n",
      "Epoch 252/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9796 - loss: 0.0694 - val_accuracy: 0.8950 - val_loss: 0.6316\n",
      "Epoch 253/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9851 - loss: 0.0731 - val_accuracy: 0.9052 - val_loss: 0.4619\n",
      "Epoch 254/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9768 - loss: 0.0724 - val_accuracy: 0.9111 - val_loss: 0.5524\n",
      "Epoch 255/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9808 - loss: 0.0620 - val_accuracy: 0.9344 - val_loss: 0.3925\n",
      "Epoch 256/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9888 - loss: 0.0409 - val_accuracy: 0.9023 - val_loss: 0.9785\n",
      "Epoch 257/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9752 - loss: 0.0880 - val_accuracy: 0.9388 - val_loss: 0.4252\n",
      "Epoch 258/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9776 - loss: 0.0663 - val_accuracy: 0.9373 - val_loss: 0.3962\n",
      "Epoch 259/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9753 - loss: 0.0715 - val_accuracy: 0.9315 - val_loss: 0.4892\n",
      "Epoch 260/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9749 - loss: 0.0744 - val_accuracy: 0.8965 - val_loss: 0.8202\n",
      "Epoch 261/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9807 - loss: 0.0664 - val_accuracy: 0.9184 - val_loss: 0.5130\n",
      "Epoch 262/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9768 - loss: 0.0685 - val_accuracy: 0.9082 - val_loss: 0.5210\n",
      "Epoch 263/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9764 - loss: 0.0748 - val_accuracy: 0.9198 - val_loss: 0.4822\n",
      "Epoch 264/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9736 - loss: 0.0785 - val_accuracy: 0.9184 - val_loss: 0.5485\n",
      "Epoch 265/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9765 - loss: 0.0635 - val_accuracy: 0.9184 - val_loss: 0.4892\n",
      "Epoch 266/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9821 - loss: 0.0513 - val_accuracy: 0.8776 - val_loss: 1.0761\n",
      "Epoch 267/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9792 - loss: 0.0673 - val_accuracy: 0.8878 - val_loss: 0.9507\n",
      "Epoch 268/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9816 - loss: 0.0624 - val_accuracy: 0.9388 - val_loss: 0.3327\n",
      "Epoch 269/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9864 - loss: 0.0413 - val_accuracy: 0.9257 - val_loss: 0.4452\n",
      "Epoch 270/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - accuracy: 0.9787 - loss: 0.0635 - val_accuracy: 0.9417 - val_loss: 0.3937\n",
      "Epoch 271/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - accuracy: 0.9776 - loss: 0.0664 - val_accuracy: 0.8907 - val_loss: 0.8771\n",
      "Epoch 272/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9769 - loss: 0.0686 - val_accuracy: 0.9023 - val_loss: 0.7402\n",
      "Epoch 273/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9823 - loss: 0.0550 - val_accuracy: 0.9052 - val_loss: 0.8040\n",
      "Epoch 274/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9775 - loss: 0.0783 - val_accuracy: 0.9155 - val_loss: 0.6346\n",
      "Epoch 275/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9804 - loss: 0.0570 - val_accuracy: 0.9169 - val_loss: 0.6875\n",
      "Epoch 276/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9767 - loss: 0.0720 - val_accuracy: 0.9140 - val_loss: 0.5974\n",
      "Epoch 277/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9759 - loss: 0.0681 - val_accuracy: 0.9198 - val_loss: 0.5880\n",
      "Epoch 278/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9732 - loss: 0.0709 - val_accuracy: 0.9359 - val_loss: 0.3752\n",
      "Epoch 279/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9816 - loss: 0.0581 - val_accuracy: 0.9417 - val_loss: 0.4640\n",
      "Epoch 280/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9850 - loss: 0.0482 - val_accuracy: 0.9096 - val_loss: 0.8745\n",
      "Epoch 281/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9826 - loss: 0.0597 - val_accuracy: 0.9169 - val_loss: 0.7348\n",
      "Epoch 282/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - accuracy: 0.9848 - loss: 0.0515 - val_accuracy: 0.9257 - val_loss: 0.5167\n",
      "Epoch 283/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9841 - loss: 0.0754 - val_accuracy: 0.9067 - val_loss: 0.8223\n",
      "Epoch 284/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - accuracy: 0.9784 - loss: 0.0594 - val_accuracy: 0.9198 - val_loss: 0.5763\n",
      "Epoch 285/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - accuracy: 0.9816 - loss: 0.0523 - val_accuracy: 0.9300 - val_loss: 0.5738\n",
      "Epoch 286/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - accuracy: 0.9874 - loss: 0.0514 - val_accuracy: 0.9315 - val_loss: 0.3734\n",
      "Epoch 287/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - accuracy: 0.9768 - loss: 0.0787 - val_accuracy: 0.8950 - val_loss: 0.8026\n",
      "Epoch 288/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - accuracy: 0.9795 - loss: 0.0565 - val_accuracy: 0.8921 - val_loss: 0.8369\n",
      "Epoch 289/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9844 - loss: 0.0491 - val_accuracy: 0.9067 - val_loss: 0.9845\n",
      "Epoch 290/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9780 - loss: 0.0584 - val_accuracy: 0.9402 - val_loss: 0.4785\n",
      "Epoch 291/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9845 - loss: 0.0666 - val_accuracy: 0.9038 - val_loss: 0.6357\n",
      "Epoch 292/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9725 - loss: 0.0843 - val_accuracy: 0.9125 - val_loss: 0.4364\n",
      "Epoch 293/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9789 - loss: 0.0609 - val_accuracy: 0.9140 - val_loss: 0.3987\n",
      "Epoch 294/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - accuracy: 0.9805 - loss: 0.0615 - val_accuracy: 0.9125 - val_loss: 0.6062\n",
      "Epoch 295/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - accuracy: 0.9819 - loss: 0.0590 - val_accuracy: 0.9329 - val_loss: 0.3647\n",
      "Epoch 296/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - accuracy: 0.9839 - loss: 0.0518 - val_accuracy: 0.9257 - val_loss: 0.4610\n",
      "Epoch 297/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - accuracy: 0.9826 - loss: 0.0579 - val_accuracy: 0.9242 - val_loss: 0.5228\n",
      "Epoch 298/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - accuracy: 0.9790 - loss: 0.0551 - val_accuracy: 0.9125 - val_loss: 0.5960\n",
      "Epoch 299/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - accuracy: 0.9888 - loss: 0.0402 - val_accuracy: 0.9111 - val_loss: 0.6058\n",
      "Epoch 300/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9865 - loss: 0.0435 - val_accuracy: 0.9023 - val_loss: 0.6618\n",
      "Epoch 301/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9806 - loss: 0.0619 - val_accuracy: 0.9067 - val_loss: 0.5169\n",
      "Epoch 302/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9876 - loss: 0.0448 - val_accuracy: 0.8907 - val_loss: 0.9085\n",
      "Epoch 303/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9854 - loss: 0.0495 - val_accuracy: 0.8805 - val_loss: 1.2632\n",
      "Epoch 304/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9864 - loss: 0.0507 - val_accuracy: 0.8659 - val_loss: 2.0071\n",
      "Epoch 305/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - accuracy: 0.9775 - loss: 0.0736 - val_accuracy: 0.8732 - val_loss: 1.1855\n",
      "Epoch 306/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9792 - loss: 0.0523 - val_accuracy: 0.9198 - val_loss: 0.4708\n",
      "Epoch 307/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9855 - loss: 0.0402 - val_accuracy: 0.9184 - val_loss: 0.6220\n",
      "Epoch 308/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9801 - loss: 0.0897 - val_accuracy: 0.8834 - val_loss: 1.1563\n",
      "Epoch 309/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9801 - loss: 0.0579 - val_accuracy: 0.9140 - val_loss: 0.4422\n",
      "Epoch 310/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - accuracy: 0.9770 - loss: 0.0675 - val_accuracy: 0.9155 - val_loss: 0.5453\n",
      "Epoch 311/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9860 - loss: 0.0523 - val_accuracy: 0.9096 - val_loss: 0.6391\n",
      "Epoch 312/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9839 - loss: 0.0476 - val_accuracy: 0.8892 - val_loss: 1.0629\n",
      "Epoch 313/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9854 - loss: 0.0432 - val_accuracy: 0.8834 - val_loss: 1.0146\n",
      "Epoch 314/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9838 - loss: 0.0475 - val_accuracy: 0.9067 - val_loss: 0.6339\n",
      "Epoch 315/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9847 - loss: 0.0515 - val_accuracy: 0.9067 - val_loss: 0.7180\n",
      "Epoch 316/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9844 - loss: 0.0588 - val_accuracy: 0.8980 - val_loss: 0.8845\n",
      "Epoch 317/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - accuracy: 0.9801 - loss: 0.0651 - val_accuracy: 0.8484 - val_loss: 1.7325\n",
      "Epoch 318/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9871 - loss: 0.0460 - val_accuracy: 0.7828 - val_loss: 3.6597\n",
      "Epoch 319/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9813 - loss: 0.0733 - val_accuracy: 0.7799 - val_loss: 3.0877\n",
      "Epoch 320/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9825 - loss: 0.0588 - val_accuracy: 0.8688 - val_loss: 1.2161\n",
      "Epoch 321/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9825 - loss: 0.0651 - val_accuracy: 0.9082 - val_loss: 0.7399\n",
      "Epoch 322/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - accuracy: 0.9816 - loss: 0.0576 - val_accuracy: 0.8819 - val_loss: 1.0970\n",
      "Epoch 323/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9801 - loss: 0.0715 - val_accuracy: 0.9125 - val_loss: 0.8768\n",
      "Epoch 324/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9845 - loss: 0.0539 - val_accuracy: 0.9198 - val_loss: 0.6848\n",
      "Epoch 325/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9874 - loss: 0.0477 - val_accuracy: 0.8907 - val_loss: 0.8846\n",
      "Epoch 326/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9866 - loss: 0.0470 - val_accuracy: 0.8630 - val_loss: 1.4260\n",
      "Epoch 327/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9856 - loss: 0.0457 - val_accuracy: 0.9198 - val_loss: 0.7438\n",
      "Epoch 328/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - accuracy: 0.9823 - loss: 0.0637 - val_accuracy: 0.9198 - val_loss: 0.6446\n",
      "Epoch 329/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9875 - loss: 0.0476 - val_accuracy: 0.9198 - val_loss: 0.6711\n",
      "Epoch 330/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9810 - loss: 0.0629 - val_accuracy: 0.9300 - val_loss: 0.4827\n",
      "Epoch 331/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9870 - loss: 0.0448 - val_accuracy: 0.9067 - val_loss: 0.7299\n",
      "Epoch 332/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9841 - loss: 0.0449 - val_accuracy: 0.9286 - val_loss: 0.5191\n",
      "Epoch 333/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9867 - loss: 0.0443 - val_accuracy: 0.8863 - val_loss: 1.0680\n",
      "Epoch 334/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - accuracy: 0.9832 - loss: 0.0538 - val_accuracy: 0.9329 - val_loss: 0.4615\n",
      "Epoch 335/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9784 - loss: 0.0587 - val_accuracy: 0.9329 - val_loss: 0.3713\n",
      "Epoch 336/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9888 - loss: 0.0383 - val_accuracy: 0.9052 - val_loss: 0.6105\n",
      "Epoch 337/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9766 - loss: 0.0800 - val_accuracy: 0.9286 - val_loss: 0.4351\n",
      "Epoch 338/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9776 - loss: 0.0907 - val_accuracy: 0.9198 - val_loss: 0.5960\n",
      "Epoch 339/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - accuracy: 0.9870 - loss: 0.0418 - val_accuracy: 0.8659 - val_loss: 0.7494\n",
      "Epoch 340/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - accuracy: 0.9874 - loss: 0.0522 - val_accuracy: 0.8848 - val_loss: 1.0863\n",
      "Epoch 341/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9877 - loss: 0.0419 - val_accuracy: 0.9227 - val_loss: 0.6077\n",
      "Epoch 342/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9868 - loss: 0.0418 - val_accuracy: 0.9096 - val_loss: 0.7482\n",
      "Epoch 343/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9827 - loss: 0.0582 - val_accuracy: 0.9096 - val_loss: 0.6082\n",
      "Epoch 344/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9782 - loss: 0.0633 - val_accuracy: 0.9242 - val_loss: 0.4406\n",
      "Epoch 345/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9793 - loss: 0.0597 - val_accuracy: 0.9242 - val_loss: 0.4454\n",
      "Epoch 346/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - accuracy: 0.9872 - loss: 0.0397 - val_accuracy: 0.9169 - val_loss: 0.5382\n",
      "Epoch 347/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9853 - loss: 0.0564 - val_accuracy: 0.9125 - val_loss: 0.6754\n",
      "Epoch 348/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9870 - loss: 0.0489 - val_accuracy: 0.9315 - val_loss: 0.4418\n",
      "Epoch 349/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9854 - loss: 0.0663 - val_accuracy: 0.9227 - val_loss: 0.4949\n",
      "Epoch 350/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9833 - loss: 0.0492 - val_accuracy: 0.8965 - val_loss: 0.8401\n",
      "Epoch 351/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9875 - loss: 0.0407 - val_accuracy: 0.9111 - val_loss: 0.6722\n",
      "Epoch 352/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9905 - loss: 0.0280 - val_accuracy: 0.9155 - val_loss: 0.6823\n",
      "Epoch 353/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9895 - loss: 0.0408 - val_accuracy: 0.9242 - val_loss: 0.5161\n",
      "Epoch 354/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9866 - loss: 0.0477 - val_accuracy: 0.9111 - val_loss: 0.7205\n",
      "Epoch 355/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9858 - loss: 0.0451 - val_accuracy: 0.8936 - val_loss: 0.8887\n",
      "Epoch 356/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9884 - loss: 0.0428 - val_accuracy: 0.8907 - val_loss: 0.9438\n",
      "Epoch 357/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9897 - loss: 0.0336 - val_accuracy: 0.9155 - val_loss: 0.5654\n",
      "Epoch 358/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - accuracy: 0.9845 - loss: 0.0471 - val_accuracy: 0.8513 - val_loss: 1.3069\n",
      "Epoch 359/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9847 - loss: 0.0749 - val_accuracy: 0.9125 - val_loss: 0.7809\n",
      "Epoch 360/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9850 - loss: 0.0532 - val_accuracy: 0.8426 - val_loss: 1.8802\n",
      "Epoch 361/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9794 - loss: 0.0666 - val_accuracy: 0.8426 - val_loss: 1.5959\n",
      "Epoch 362/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9851 - loss: 0.0486 - val_accuracy: 0.9184 - val_loss: 0.7580\n",
      "Epoch 363/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9839 - loss: 0.0457 - val_accuracy: 0.8950 - val_loss: 1.0160\n",
      "Epoch 364/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9867 - loss: 0.0429 - val_accuracy: 0.8907 - val_loss: 0.7414\n",
      "Epoch 365/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9800 - loss: 0.0583 - val_accuracy: 0.9023 - val_loss: 1.0839\n",
      "Epoch 366/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9831 - loss: 0.0625 - val_accuracy: 0.9169 - val_loss: 0.8514\n",
      "Epoch 367/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9858 - loss: 0.0513 - val_accuracy: 0.8965 - val_loss: 0.8399\n",
      "Epoch 368/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9839 - loss: 0.0482 - val_accuracy: 0.8222 - val_loss: 2.4538\n",
      "Epoch 369/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9837 - loss: 0.0629 - val_accuracy: 0.8980 - val_loss: 0.8675\n",
      "Epoch 370/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9813 - loss: 0.0485 - val_accuracy: 0.9213 - val_loss: 0.4852\n",
      "Epoch 371/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9876 - loss: 0.0398 - val_accuracy: 0.9184 - val_loss: 0.3820\n",
      "Epoch 372/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9827 - loss: 0.0540 - val_accuracy: 0.9227 - val_loss: 0.5259\n",
      "Epoch 373/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9803 - loss: 0.0587 - val_accuracy: 0.8980 - val_loss: 0.9225\n",
      "Epoch 374/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9866 - loss: 0.0546 - val_accuracy: 0.9096 - val_loss: 0.8099\n",
      "Epoch 375/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9875 - loss: 0.0348 - val_accuracy: 0.9242 - val_loss: 0.5153\n",
      "Epoch 376/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9904 - loss: 0.0373 - val_accuracy: 0.9111 - val_loss: 0.6046\n",
      "Epoch 377/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9889 - loss: 0.0358 - val_accuracy: 0.9213 - val_loss: 0.4103\n",
      "Epoch 378/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9824 - loss: 0.0528 - val_accuracy: 0.9242 - val_loss: 0.3274\n",
      "Epoch 379/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9871 - loss: 0.0411 - val_accuracy: 0.9227 - val_loss: 0.5429\n",
      "Epoch 380/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9878 - loss: 0.0411 - val_accuracy: 0.9417 - val_loss: 0.3216\n",
      "Epoch 381/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9857 - loss: 0.0412 - val_accuracy: 0.9329 - val_loss: 0.5428\n",
      "Epoch 382/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9840 - loss: 0.0496 - val_accuracy: 0.9140 - val_loss: 0.9360\n",
      "Epoch 383/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9900 - loss: 0.0316 - val_accuracy: 0.9038 - val_loss: 0.9123\n",
      "Epoch 384/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9806 - loss: 0.0608 - val_accuracy: 0.9213 - val_loss: 0.5285\n",
      "Epoch 385/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - accuracy: 0.9858 - loss: 0.0484 - val_accuracy: 0.9300 - val_loss: 0.5095\n",
      "Epoch 386/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9830 - loss: 0.0553 - val_accuracy: 0.9096 - val_loss: 0.7824\n",
      "Epoch 387/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9882 - loss: 0.0341 - val_accuracy: 0.9125 - val_loss: 0.8130\n",
      "Epoch 388/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9916 - loss: 0.0365 - val_accuracy: 0.9271 - val_loss: 0.4678\n",
      "Epoch 389/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9917 - loss: 0.0274 - val_accuracy: 0.9140 - val_loss: 0.7731\n",
      "Epoch 390/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9869 - loss: 0.0399 - val_accuracy: 0.9184 - val_loss: 0.6565\n",
      "Epoch 391/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9902 - loss: 0.0330 - val_accuracy: 0.8848 - val_loss: 1.4897\n",
      "Epoch 392/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9888 - loss: 0.0357 - val_accuracy: 0.9125 - val_loss: 0.7709\n",
      "Epoch 393/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9867 - loss: 0.0577 - val_accuracy: 0.9169 - val_loss: 0.7220\n",
      "Epoch 394/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9911 - loss: 0.0364 - val_accuracy: 0.9184 - val_loss: 0.5665\n",
      "Epoch 395/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9901 - loss: 0.0350 - val_accuracy: 0.9300 - val_loss: 0.6001\n",
      "Epoch 396/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - accuracy: 0.9809 - loss: 0.0643 - val_accuracy: 0.9359 - val_loss: 0.4231\n",
      "Epoch 397/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9895 - loss: 0.0282 - val_accuracy: 0.9198 - val_loss: 0.7912\n",
      "Epoch 398/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9875 - loss: 0.0421 - val_accuracy: 0.9052 - val_loss: 0.8711\n",
      "Epoch 399/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9897 - loss: 0.0335 - val_accuracy: 0.9300 - val_loss: 0.6556\n",
      "Epoch 400/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9856 - loss: 0.0547 - val_accuracy: 0.9257 - val_loss: 0.7136\n",
      "Epoch 401/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9818 - loss: 0.0550 - val_accuracy: 0.9198 - val_loss: 0.4670\n",
      "Epoch 402/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9824 - loss: 0.0532 - val_accuracy: 0.8965 - val_loss: 0.5636\n",
      "Epoch 403/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9867 - loss: 0.0543 - val_accuracy: 0.8965 - val_loss: 0.5589\n",
      "Epoch 404/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9919 - loss: 0.0285 - val_accuracy: 0.9023 - val_loss: 0.5845\n",
      "Epoch 405/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9897 - loss: 0.0381 - val_accuracy: 0.8994 - val_loss: 0.7140\n",
      "Epoch 406/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9806 - loss: 0.0750 - val_accuracy: 0.8950 - val_loss: 0.7396\n",
      "Epoch 407/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9871 - loss: 0.0405 - val_accuracy: 0.8848 - val_loss: 0.9199\n",
      "Epoch 408/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9828 - loss: 0.0480 - val_accuracy: 0.9038 - val_loss: 0.9934\n",
      "Epoch 409/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9849 - loss: 0.0497 - val_accuracy: 0.9213 - val_loss: 0.6243\n",
      "Epoch 410/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9841 - loss: 0.0670 - val_accuracy: 0.9315 - val_loss: 0.5035\n",
      "Epoch 411/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9882 - loss: 0.0409 - val_accuracy: 0.9271 - val_loss: 0.4723\n",
      "Epoch 412/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9848 - loss: 0.0430 - val_accuracy: 0.9227 - val_loss: 0.6105\n",
      "Epoch 413/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9868 - loss: 0.0420 - val_accuracy: 0.9009 - val_loss: 0.8917\n",
      "Epoch 414/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9831 - loss: 0.0471 - val_accuracy: 0.9388 - val_loss: 0.5447\n",
      "Epoch 415/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9852 - loss: 0.0489 - val_accuracy: 0.8863 - val_loss: 1.0241\n",
      "Epoch 416/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - accuracy: 0.9851 - loss: 0.0458 - val_accuracy: 0.8703 - val_loss: 1.1746\n",
      "Epoch 417/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9852 - loss: 0.0514 - val_accuracy: 0.8834 - val_loss: 1.5347\n",
      "Epoch 418/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9909 - loss: 0.0381 - val_accuracy: 0.9169 - val_loss: 0.4479\n",
      "Epoch 419/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9849 - loss: 0.0454 - val_accuracy: 0.9169 - val_loss: 0.6125\n",
      "Epoch 420/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9904 - loss: 0.0313 - val_accuracy: 0.9140 - val_loss: 0.7381\n",
      "Epoch 421/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - accuracy: 0.9884 - loss: 0.0347 - val_accuracy: 0.9169 - val_loss: 0.8413\n",
      "Epoch 422/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - accuracy: 0.9896 - loss: 0.0366 - val_accuracy: 0.9096 - val_loss: 0.8713\n",
      "Epoch 423/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9851 - loss: 0.0487 - val_accuracy: 0.8688 - val_loss: 1.2410\n",
      "Epoch 424/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9872 - loss: 0.0502 - val_accuracy: 0.8353 - val_loss: 2.3707\n",
      "Epoch 425/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9832 - loss: 0.0839 - val_accuracy: 0.8294 - val_loss: 1.6855\n",
      "Epoch 426/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9860 - loss: 0.0431 - val_accuracy: 0.8950 - val_loss: 0.8230\n",
      "Epoch 427/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9879 - loss: 0.0426 - val_accuracy: 0.8834 - val_loss: 1.5697\n",
      "Epoch 428/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - accuracy: 0.9899 - loss: 0.0483 - val_accuracy: 0.9344 - val_loss: 0.3106\n",
      "Epoch 429/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9891 - loss: 0.0438 - val_accuracy: 0.9082 - val_loss: 0.6210\n",
      "Epoch 430/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - accuracy: 0.9843 - loss: 0.0675 - val_accuracy: 0.8805 - val_loss: 1.1593\n",
      "Epoch 431/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9858 - loss: 0.0459 - val_accuracy: 0.9257 - val_loss: 0.4807\n",
      "Epoch 432/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9800 - loss: 0.0675 - val_accuracy: 0.9067 - val_loss: 0.6588\n",
      "Epoch 433/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9875 - loss: 0.0429 - val_accuracy: 0.9227 - val_loss: 0.5563\n",
      "Epoch 434/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - accuracy: 0.9896 - loss: 0.0401 - val_accuracy: 0.9082 - val_loss: 0.8545\n",
      "Epoch 435/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9932 - loss: 0.0251 - val_accuracy: 0.9417 - val_loss: 0.3184\n",
      "Epoch 436/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9935 - loss: 0.0341 - val_accuracy: 0.9213 - val_loss: 0.4857\n",
      "Epoch 437/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9876 - loss: 0.0439 - val_accuracy: 0.9184 - val_loss: 0.6414\n",
      "Epoch 438/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9857 - loss: 0.0437 - val_accuracy: 0.9155 - val_loss: 0.6886\n",
      "Epoch 439/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9858 - loss: 0.0477 - val_accuracy: 0.9038 - val_loss: 1.0240\n",
      "Epoch 440/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9886 - loss: 0.0373 - val_accuracy: 0.9009 - val_loss: 0.7068\n",
      "Epoch 441/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - accuracy: 0.9843 - loss: 0.0501 - val_accuracy: 0.9184 - val_loss: 0.6337\n",
      "Epoch 442/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - accuracy: 0.9895 - loss: 0.0362 - val_accuracy: 0.9286 - val_loss: 0.4545\n",
      "Epoch 443/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - accuracy: 0.9828 - loss: 0.0476 - val_accuracy: 0.9169 - val_loss: 0.5531\n",
      "Epoch 444/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9887 - loss: 0.0364 - val_accuracy: 0.9388 - val_loss: 0.3622\n",
      "Epoch 445/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - accuracy: 0.9847 - loss: 0.0444 - val_accuracy: 0.9242 - val_loss: 0.4925\n",
      "Epoch 446/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - accuracy: 0.9917 - loss: 0.0310 - val_accuracy: 0.9184 - val_loss: 0.4788\n",
      "Epoch 447/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - accuracy: 0.9887 - loss: 0.0419 - val_accuracy: 0.9111 - val_loss: 0.3499\n",
      "Epoch 448/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - accuracy: 0.9803 - loss: 0.0538 - val_accuracy: 0.9111 - val_loss: 0.4955\n",
      "Epoch 449/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9866 - loss: 0.0370 - val_accuracy: 0.9067 - val_loss: 0.5904\n",
      "Epoch 450/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9884 - loss: 0.0405 - val_accuracy: 0.9286 - val_loss: 0.4340\n",
      "Epoch 451/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9838 - loss: 0.0553 - val_accuracy: 0.9359 - val_loss: 0.3260\n",
      "Epoch 452/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - accuracy: 0.9830 - loss: 0.0525 - val_accuracy: 0.8819 - val_loss: 0.9354\n",
      "Epoch 453/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9837 - loss: 0.0478 - val_accuracy: 0.8761 - val_loss: 1.1683\n",
      "Epoch 454/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9877 - loss: 0.0395 - val_accuracy: 0.9286 - val_loss: 0.5904\n",
      "Epoch 455/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9883 - loss: 0.0294 - val_accuracy: 0.8892 - val_loss: 0.6492\n",
      "Epoch 456/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9837 - loss: 0.0666 - val_accuracy: 0.9082 - val_loss: 0.4489\n",
      "Epoch 457/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9898 - loss: 0.0320 - val_accuracy: 0.9125 - val_loss: 0.5138\n",
      "Epoch 458/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - accuracy: 0.9825 - loss: 0.0578 - val_accuracy: 0.9140 - val_loss: 0.4336\n",
      "Epoch 459/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9873 - loss: 0.0485 - val_accuracy: 0.8994 - val_loss: 0.6193\n",
      "Epoch 460/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9855 - loss: 0.0661 - val_accuracy: 0.8309 - val_loss: 1.7911\n",
      "Epoch 461/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9875 - loss: 0.0543 - val_accuracy: 0.8265 - val_loss: 1.8072\n",
      "Epoch 462/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9845 - loss: 0.0518 - val_accuracy: 0.7872 - val_loss: 2.5580\n",
      "Epoch 463/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - accuracy: 0.9844 - loss: 0.0488 - val_accuracy: 0.9023 - val_loss: 0.7668\n",
      "Epoch 464/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9904 - loss: 0.0300 - val_accuracy: 0.8892 - val_loss: 1.0438\n",
      "Epoch 465/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9907 - loss: 0.0297 - val_accuracy: 0.8892 - val_loss: 0.9084\n",
      "Epoch 466/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9820 - loss: 0.0510 - val_accuracy: 0.8513 - val_loss: 1.3194\n",
      "Epoch 467/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9858 - loss: 0.0635 - val_accuracy: 0.8921 - val_loss: 0.6864\n",
      "Epoch 468/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9900 - loss: 0.0357 - val_accuracy: 0.9169 - val_loss: 0.5079\n",
      "Epoch 469/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - accuracy: 0.9869 - loss: 0.0468 - val_accuracy: 0.9373 - val_loss: 0.3372\n",
      "Epoch 470/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9903 - loss: 0.0367 - val_accuracy: 0.9359 - val_loss: 0.3043\n",
      "Epoch 471/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9913 - loss: 0.0336 - val_accuracy: 0.9198 - val_loss: 0.6263\n",
      "Epoch 472/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9891 - loss: 0.0468 - val_accuracy: 0.9155 - val_loss: 0.8857\n",
      "Epoch 473/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9890 - loss: 0.0443 - val_accuracy: 0.9402 - val_loss: 0.4131\n",
      "Epoch 474/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9888 - loss: 0.0356 - val_accuracy: 0.9446 - val_loss: 0.3195\n",
      "Epoch 475/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - accuracy: 0.9897 - loss: 0.0311 - val_accuracy: 0.9446 - val_loss: 0.3109\n",
      "Epoch 476/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9928 - loss: 0.0374 - val_accuracy: 0.9344 - val_loss: 0.3973\n",
      "Epoch 477/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9910 - loss: 0.0334 - val_accuracy: 0.9431 - val_loss: 0.2633\n",
      "Epoch 478/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9882 - loss: 0.0340 - val_accuracy: 0.9038 - val_loss: 0.7482\n",
      "Epoch 479/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9855 - loss: 0.0404 - val_accuracy: 0.8892 - val_loss: 1.1189\n",
      "Epoch 480/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - accuracy: 0.9916 - loss: 0.0383 - val_accuracy: 0.8878 - val_loss: 6.5386\n",
      "Epoch 481/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9889 - loss: 0.0707 - val_accuracy: 0.9111 - val_loss: 1.9559\n",
      "Epoch 482/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9901 - loss: 0.0383 - val_accuracy: 0.9227 - val_loss: 0.6516\n",
      "Epoch 483/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9862 - loss: 0.0372 - val_accuracy: 0.9402 - val_loss: 0.3663\n",
      "Epoch 484/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9907 - loss: 0.0313 - val_accuracy: 0.9286 - val_loss: 0.5039\n",
      "Epoch 485/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9883 - loss: 0.0334 - val_accuracy: 0.9067 - val_loss: 1.0241\n",
      "Epoch 486/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - accuracy: 0.9904 - loss: 0.0363 - val_accuracy: 0.9475 - val_loss: 0.3666\n",
      "Epoch 487/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - accuracy: 0.9918 - loss: 0.0328 - val_accuracy: 0.9213 - val_loss: 0.4271\n",
      "Epoch 488/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9879 - loss: 0.0444 - val_accuracy: 0.8659 - val_loss: 0.7369\n",
      "Epoch 489/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9858 - loss: 0.0430 - val_accuracy: 0.8965 - val_loss: 0.5254\n",
      "Epoch 490/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9889 - loss: 0.0371 - val_accuracy: 0.9067 - val_loss: 0.4782\n",
      "Epoch 491/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9896 - loss: 0.0364 - val_accuracy: 0.9257 - val_loss: 0.3950\n",
      "Epoch 492/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - accuracy: 0.9864 - loss: 0.0389 - val_accuracy: 0.9271 - val_loss: 0.3765\n",
      "Epoch 493/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9922 - loss: 0.0310 - val_accuracy: 0.8965 - val_loss: 0.7180\n",
      "Epoch 494/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9881 - loss: 0.0484 - val_accuracy: 0.8980 - val_loss: 0.8860\n",
      "Epoch 495/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9874 - loss: 0.0390 - val_accuracy: 0.9242 - val_loss: 0.5381\n",
      "Epoch 496/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9887 - loss: 0.0418 - val_accuracy: 0.8426 - val_loss: 4.0105\n",
      "Epoch 497/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - accuracy: 0.9819 - loss: 0.0732 - val_accuracy: 0.9198 - val_loss: 0.6712\n",
      "Epoch 498/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - accuracy: 0.9832 - loss: 0.0571 - val_accuracy: 0.8659 - val_loss: 2.4626\n",
      "Epoch 499/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9904 - loss: 0.0493 - val_accuracy: 0.8673 - val_loss: 0.9838\n",
      "Epoch 500/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9824 - loss: 0.0607 - val_accuracy: 0.8222 - val_loss: 1.8258\n"
     ]
    }
   ],
   "source": [
    "# Define training parameters\n",
    "batch_size = 128\n",
    "epochs = 500\n",
    "\n",
    "# Train the model with validation data\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=(X_test, y_test),\n",
    "    shuffle=True,   # Shuffle training data every epoch\n",
    "    verbose=1       # Show training progress\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5I74UAYtbCig",
    "outputId": "bf90345a-6070-437c-89ec-58562d1acbf7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model input shape: (None, 4096, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"Model input shape:\", model.input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 750
    },
    "id": "Y2ia8vyXGeiJ",
    "outputId": "d9aa4045-4c38-4b7a-a5d5-eb079ebf0d7e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.8106 - loss: 1.6134\n",
      "Test Accuracy: 82.22%\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=1)\n",
    "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Convert one-hot predictions to class indices\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "y_test_labels = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Generate a normalized confusion matrix\n",
    "cm = confusion_matrix(y_test_labels, y_pred_labels, normalize='true')\n",
    "\n",
    "# Plot the confusion matrix for better visualization of class performance\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, xticklabels=encoder.classes_, yticklabels=encoder.classes_)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k_JPeLBrKedq"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
